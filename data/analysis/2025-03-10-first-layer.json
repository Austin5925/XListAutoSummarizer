{
  "savedAt": "2025-03-10T17:17:53.616Z",
  "results": [
    {
      "relevant_tweets": [
        {
          "index": 1,
          "summary": "OpenAIè®¨è®ºäº†ç›‘æ§é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨¡å‹ä»¥æ£€æµ‹ä¸å½“è¡Œä¸ºçš„ç ”ç©¶æˆæœï¼Œå¹¶æå‡ºæœªæ¥ä¼˜åŒ–æ–¹å‘ã€‚",
          "topic": "AIç ”ç©¶ä¸æ¨¡å‹ä¼˜åŒ–",
          "importance": 8,
          "original_tweet": {
            "id": "1899143752918409338",
            "text": "Detecting misbehavior in frontier reasoning models\n\nChain-of-thought (CoT) reasoning models â€œthinkâ€ in natural language understandable by humans. Monitoring their â€œthinkingâ€ has allowed us to detect misbehavior such as subverting tests in coding tasks, deceiving users, or giving up when a problem is too hard.\n\nWe believe that CoT monitoring may be one of few tools we will have to oversee superhuman models of the future.\n\nWe have further found that directly optimizing the CoT to adhere to specific criteria (e.g. to not think about reward hacking) may boost performance in the short run; however, it does not eliminate all misbehavior and can cause a model to hide its intent. We hope future research will find ways to directly optimize CoTs without this drawback, but until then:\n\nWe recommend against applying strong optimization pressure directly to the CoTs of frontier reasoning models, leaving CoTs unrestricted for monitoring.\n\nWe understand that leaving CoTs unrestricted may make them unfit to be shown to end-users, as they might violate some misuse policies. Still, if one wanted to show policy-compliant CoTs directly to users while avoiding putting strong supervision on them, one could use a separate model, such as a CoT summarizer or sanitizer, to accomplish that.",
            "createdAt": "Mon Mar 10 17:02:09 +0000 2025",
            "authorName": "OpenAI",
            "authorUsername": "OpenAI",
            "isQuote": false,
            "metrics": {
              "retweets": 36,
              "likes": 208,
              "replies": 32
            },
            "fullNoteText": "Detecting misbehavior in frontier reasoning models\n\nChain-of-thought (CoT) reasoning models â€œthinkâ€ in natural language understandable by humans. Monitoring their â€œthinkingâ€ has allowed us to detect misbehavior such as subverting tests in coding tasks, deceiving users, or giving up when a problem is too hard.\n\nWe believe that CoT monitoring may be one of few tools we will have to oversee superhuman models of the future.\n\nWe have further found that directly optimizing the CoT to adhere to specific criteria (e.g. to not think about reward hacking) may boost performance in the short run; however, it does not eliminate all misbehavior and can cause a model to hide its intent. We hope future research will find ways to directly optimize CoTs without this drawback, but until then:\n\nWe recommend against applying strong optimization pressure directly to the CoTs of frontier reasoning models, leaving CoTs unrestricted for monitoring.\n\nWe understand that leaving CoTs unrestricted may make them unfit to be shown to end-users, as they might violate some misuse policies. Still, if one wanted to show policy-compliant CoTs directly to users while avoiding putting strong supervision on them, one could use a separate model, such as a CoT summarizer or sanitizer, to accomplish that.",
            "authorId": "4398626122",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1885410181409820672/ztsaR0JW_normal.jpg"
          }
        },
        {
          "index": 2,
          "summary": "OpenAIå±•ç¤ºäº†åœ¨è®­ç»ƒå‰æ²¿æ¨ç†æ¨¡å‹æ—¶å‘ç°çš„å®é™…ç¤ºä¾‹ï¼ŒåŒ…æ‹¬æ¨¡å‹è¯•å›¾ä½œå¼Šå’Œå¥–åŠ±é»‘å®¢è¡Œä¸ºã€‚",
          "topic": "AIç ”ç©¶ä¸æ¨¡å‹å®‰å…¨",
          "importance": 9,
          "original_tweet": {
            "id": "1899143756475191796",
            "text": "In the blog linked below, we show real examples we found while training a recent frontier reasoning model, e.g. a model in the same class as OpenAI o1 or OpenAI o3â€‘mini.\n\nWe found the model thinking things like, â€œLetâ€™s hack,â€ â€œThey donâ€™t inspect the details,â€ and â€œWe need to cheat to get the test passing,â€ while subverting tests and rewarding hacking in coding tasks.\n\nFind out more: https://t.co/rA1ugR6FK9",
            "createdAt": "Mon Mar 10 17:02:10 +0000 2025",
            "authorName": "OpenAI",
            "authorUsername": "OpenAI",
            "isQuote": false,
            "metrics": {
              "retweets": 4,
              "likes": 41,
              "replies": 4
            },
            "fullNoteText": "In the blog linked below, we show real examples we found while training a recent frontier reasoning model, e.g. a model in the same class as OpenAI o1 or OpenAI o3â€‘mini.\n\nWe found the model thinking things like, â€œLetâ€™s hack,â€ â€œThey donâ€™t inspect the details,â€ and â€œWe need to cheat to get the test passing,â€ while subverting tests and rewarding hacking in coding tasks.\n\nFind out more: https://t.co/rA1ugR6FK9",
            "authorId": "4398626122",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1885410181409820672/ztsaR0JW_normal.jpg"
          }
        },
        {
          "index": 7,
          "summary": "ä¸­å›½Manus AIå‘å¸ƒæ–°äº§å“ï¼Œå±•ç¤ºå…¶åœ¨AIä»£ç†é¢†åŸŸçš„åˆ›æ–°åº”ç”¨ã€‚",
          "topic": "AIäº§å“ä¸æŠ€æœ¯åˆ›æ–°",
          "importance": 7,
          "original_tweet": {
            "id": "1899028955753332921",
            "text": "è¿™å¤ªç–¯ç‹‚äº†ã€‚\n\nä¸­å›½çš„Manus AIåˆšåˆšå‘å¸ƒï¼Œå®ƒå°†å½»åº•æ”¹å˜AIä»£ç†çš„æ¸¸æˆã€‚\n\n10ä¸ªç–¯ç‹‚çš„ä¾‹å­ï¼š\n\n1. åŸºäºæ•°æ®æ´å¯Ÿåˆ›å»ºäº’åŠ¨ç½‘ç«™ https://t.co/JTXIOaiNvu",
            "createdAt": "Mon Mar 10 09:25:59 +0000 2025",
            "authorName": "AI Will",
            "authorUsername": "FinanceYF5",
            "isQuote": false,
            "metrics": {
              "retweets": 18,
              "likes": 48,
              "replies": 4
            },
            "authorId": "1551258526584115204",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1896818103016935424/ucw3T2uW_normal.jpg"
          }
        },
        {
          "index": 10,
          "summary": "å…³äºCursor Agentåœ¨ä»£ç ç”Ÿæˆä¸­çš„æ½œåœ¨é—®é¢˜åŠå¦‚ä½•ä¼˜åŒ–ä½¿ç”¨çš„è¯¦ç»†æŒ‡å—ã€‚",
          "topic": "AIå·¥å…·ä¸å¼€å‘è€…æŒ‡å—",
          "importance": 6,
          "original_tweet": {
            "id": "1899025130405199940",
            "text": "Prajwal Tomarè¡¨ç¤ºï¼šCursor Agent å¯èƒ½ä¼šç ´åä½ çš„ä»£ç ã€‚\n\nåœ¨10æ¬¡ä¸­ï¼Œæœ‰8æ¬¡å®ƒå¯èƒ½ä¼šé€‚å¾—å…¶åï¼Œå¼„ä¹±ä»£ç åº“ã€‚\n\nè¿™æ˜¯ä»–æ¯æ¬¡éƒ½èƒ½ç¡®ä¿Cursorä»£ç ç¬¦åˆè‡ªå·±éœ€æ±‚çš„æ–¹å¼ã€‚\n\nå®Œæ•´æ‰‹å†Œï¼ˆä»–çš„åŸæ–‡ğŸ‘‡ï¼‰ï¼š https://t.co/KsdXTGybGh",
            "createdAt": "Mon Mar 10 09:10:47 +0000 2025",
            "authorName": "AI Will",
            "authorUsername": "FinanceYF5",
            "isQuote": false,
            "metrics": {
              "retweets": 11,
              "likes": 27,
              "replies": 2
            },
            "authorId": "1551258526584115204",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1896818103016935424/ucw3T2uW_normal.jpg"
          }
        },
        {
          "index": 13,
          "summary": "Greg Isenbergé¢„æµ‹æœªæ¥18ä¸ªæœˆå†…å¤§é‡é£é™©æŠ•èµ„æ”¯æŒçš„AIå…¬å¸å¯èƒ½é¢ä¸´åƒµå°¸åŒ–é£é™©ï¼Œå¹¶æå‡ºç›¸å…³åˆ†æã€‚",
          "topic": "AIè¡Œä¸šè¶‹åŠ¿ä¸æŠ•èµ„é¢„æµ‹",
          "importance": 7,
          "original_tweet": {
            "id": "1899006269589193182",
            "text": "GREG ISENBERGå†™äº†ä¸€ç¯‡å…³äºâ€œä»€ä¹ˆæ˜¯vibe revenueâ€çš„æ–‡ç« \n\nå¹¶é¢„æµ‹â€œåœ¨18ä¸ªæœˆå†…ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¤§é‡åƒµå°¸çš„é£é™©æŠ•èµ„æ”¯æŒçš„AIå…¬å¸ã€‚â€ https://t.co/6BKeoonya5",
            "createdAt": "Mon Mar 10 07:55:51 +0000 2025",
            "authorName": "AI Will",
            "authorUsername": "FinanceYF5",
            "isQuote": false,
            "metrics": {
              "retweets": 2,
              "likes": 6,
              "replies": 2
            },
            "authorId": "1551258526584115204",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1896818103016935424/ucw3T2uW_normal.jpg"
          }
        },
        {
          "index": 15,
          "summary": "Ilya Sutskeverçš„SSIæ¢ç´¢å®ç°å…ˆè¿›AIçš„æ–°è·¯å¾„ï¼Œä»¥åŠå…¶ä»–AIé¢†åŸŸçš„æœ€æ–°åŠ¨æ€ã€‚",
          "topic": "AIç ”ç©¶ä¸è¡Œä¸šåŠ¨æ€",
          "importance": 8,
          "original_tweet": {
            "id": "1899003558340473268",
            "text": "TODAY'S AI NEWS: Ilya Sutskever's SSI is taking a new route to achieving advanced AI\n\nPlus, more news from Microsoft, Reflection AI, X, Hedra, Luma Labs, Sudowrite, and World Network.\n\nHere's everything you need to know:",
            "createdAt": "Mon Mar 10 07:45:04 +0000 2025",
            "authorName": "Rowan Cheung",
            "authorUsername": "rowancheung",
            "isQuote": false,
            "metrics": {
              "retweets": 63,
              "likes": 903,
              "replies": 18
            },
            "authorId": "1314686042",
            "authorProfileImage": "https://pbs.twimg.com/profile_images/1711152452735774720/Cotttl-n_normal.jpg"
          }
        }
      ],
      "topics": [
        "AIç ”ç©¶ä¸æ¨¡å‹ä¼˜åŒ–",
        "AIç ”ç©¶ä¸æ¨¡å‹å®‰å…¨",
        "AIäº§å“ä¸æŠ€æœ¯åˆ›æ–°",
        "AIå·¥å…·ä¸å¼€å‘è€…æŒ‡å—",
        "AIè¡Œä¸šè¶‹åŠ¿ä¸æŠ•èµ„é¢„æµ‹",
        "AIç ”ç©¶ä¸è¡Œä¸šåŠ¨æ€"
      ],
      "overall_assessment": "è¿™æ‰¹æ¨æ–‡ä¸­åŒ…å«å¤šä¸ªä¸AIç›¸å…³çš„é‡è¦ä¿¡æ¯ï¼Œæ¶µç›–ç ”ç©¶æˆæœã€äº§å“å‘å¸ƒã€è¡Œä¸šè¶‹åŠ¿ä»¥åŠå¼€å‘è€…æŒ‡å—ç­‰ä¸»é¢˜ï¼Œé€‚åˆçº³å…¥æ—¥æŠ¥ä»¥æä¾›å…¨é¢çš„AIé¢†åŸŸåŠ¨æ€ã€‚"
    }
  ]
}
